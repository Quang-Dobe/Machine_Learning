{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Tutorial_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rB4B7FdIGJlV"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones(5)\n",
        "Y = torch.zeros(3)\n",
        "W = torch.rand((5, 3), requires_grad=True)\n",
        "B = torch.rand(3, requires_grad=True)\n",
        "Z = torch.matmul(W.T, X) + B\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(Z, Y)\n",
        "print(f\"Loss = {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADx2lnkC33VE",
        "outputId": "5e401899-dc8c-44b1-96e2-522e8784436f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 3.6166486740112305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute gradient**"
      ],
      "metadata": {
        "id": "pyYM6BFG--8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(W.grad)\n",
        "print(B.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKaJXu9r9qkh",
        "outputId": "de767402-a248-4e7d-e7d6-50e4a5ad9052"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3273, 0.3236, 0.3212],\n",
            "        [0.3273, 0.3236, 0.3212],\n",
            "        [0.3273, 0.3236, 0.3212],\n",
            "        [0.3273, 0.3236, 0.3212],\n",
            "        [0.3273, 0.3236, 0.3212]])\n",
            "tensor([0.3273, 0.3236, 0.3212])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Disable gradient tracking**"
      ],
      "metadata": {
        "id": "hlRgkt5Z_Be5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z = torch.matmul(W.T, X) + B\n",
        "print(Z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    Z = torch.matmul(W.T, X) + B\n",
        "print(Z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7iWLHub-8wP",
        "outputId": "654f05c3-767b-44ef-aa3c-007dc48e5a5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z = torch.matmul(W.T, X) + B\n",
        "Z_new = Z.detach()\n",
        "print(Z_new.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtV8MwlZ_xic",
        "outputId": "ee38d9ed-c7ab-4f57-9cc7-193d6ff22a59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = torch.eye(5, requires_grad=True)\n",
        "out = (inp + 1).pow(2)\n",
        "out.backward(torch.ones_like(inp), retain_graph=True)\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"First call:\", inp.grad)\n",
        "print(\"Inp:\", inp)\n",
        "\n",
        "out.backward(torch.ones_like(inp), retain_graph=True)\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"Second call:\", inp.grad)\n",
        "print(\"Inp:\", inp)\n",
        "\n",
        "inp.grad.zero_()\n",
        "out.backward(torch.ones_like(inp), retain_graph=True)\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"Third call:\", inp.grad)\n",
        "print(\"Inp:\", inp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--lMQX5pDw4L",
        "outputId": "d24ecb1a-de86-4497-d3d0-0fd18b7a6b48"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "First call: tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.],\n",
            "        [2., 2., 2., 2., 4.]])\n",
            "Inp: tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]], requires_grad=True)\n",
            "--------------------------------------------------\n",
            "Second call: tensor([[8., 4., 4., 4., 4.],\n",
            "        [4., 8., 4., 4., 4.],\n",
            "        [4., 4., 8., 4., 4.],\n",
            "        [4., 4., 4., 8., 4.],\n",
            "        [4., 4., 4., 4., 8.]])\n",
            "Inp: tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]], requires_grad=True)\n",
            "--------------------------------------------------\n",
            "Third call: tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.],\n",
            "        [2., 2., 2., 2., 4.]])\n",
            "Inp: tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}