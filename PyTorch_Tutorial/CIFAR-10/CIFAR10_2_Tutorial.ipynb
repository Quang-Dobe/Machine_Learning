{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_2_Tutorial.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "OI57cTjKRDN5",
        "9-rPu__mj9jA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfBin9fONYFO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset**"
      ],
      "metadata": {
        "id": "OI57cTjKRDN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load dataset**"
      ],
      "metadata": {
        "id": "9-rPu__mj9jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(), \n",
        "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")"
      ],
      "metadata": {
        "id": "sYnFKRBnNZMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n",
        "testing_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")"
      ],
      "metadata": {
        "id": "6otDT8jtRCgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = training_data.data, training_data.targets\n",
        "print(f\"Type of X: {type(X)}\")\n",
        "print(f\"Size of X: {X.shape}\")\n",
        "print(f\"Type of y: {type(y)}\")\n",
        "print(f\"Size of y: {len(y)}\")"
      ],
      "metadata": {
        "id": "cKq7_FFskC1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = {i: y.count(i) for i in range(10)}\n",
        "print(f\"Number of each class in training_data: \\n{num_class}\")"
      ],
      "metadata": {
        "id": "9-Kt3tWxlbYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "gxCabBhbRIUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.Stage_1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.Stage_2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.Stage_3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.Stage_4 = nn.Flatten(start_dim=1, end_dim=-1)\n",
        "\n",
        "        self.Stage_5 = nn.Sequential(\n",
        "            nn.Linear(4096, 1024, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        Stage_1 = self.Stage_1(X)\n",
        "        Stage_2 = self.Stage_2(Stage_1)\n",
        "        Stage_3 = self.Stage_3(Stage_2)\n",
        "        Stage_4 = self.Stage_4(Stage_3)\n",
        "        Stage_5 = self.Stage_5(Stage_4)\n",
        "        return Stage_5\n",
        "\n",
        "    def train(self, training_data, optimizer=\"sgd\", batch_size=64, epochs=10, lr=5e-6):\n",
        "        training_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        Loss = nn.CrossEntropyLoss()\n",
        "        if optimizer.lower()==\"adam\":\n",
        "            Optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "        else:\n",
        "            Optimizer = torch.optim.SGD(self.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "        print(\"-----------------------------------------------\")\n",
        "        for i in range(epochs):\n",
        "            for batch, (X, y) in enumerate(training_dataloader):\n",
        "                y_pre = self.forward(X)\n",
        "                loss_fn = Loss(y_pre, y)\n",
        "\n",
        "                Optimizer.zero_grad()\n",
        "                loss_fn.backward()\n",
        "                Optimizer.step()\n",
        "            print(f\"-- Epoch {i}/{epochs}: Loss = {loss_fn}\")\n",
        "    \n",
        "    def evaluate(self, testing_data):\n",
        "        corrected, total = 0, 0\n",
        "        testing_dataloader = DataLoader(testing_data, batch_size=1, shuffle=False)\n",
        "\n",
        "        for batch, (X, y) in enumerate(testing_dataloader):\n",
        "            y_pre = self.forward(X)\n",
        "            if (y_pre.argmax().item() == y.item()):\n",
        "                corrected += 1\n",
        "            total += 1\n",
        "        return (corrected / total) * 100"
      ],
      "metadata": {
        "id": "epdRpTF_RKEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.train(training_data, optimizer='adam', epochs=3, lr=1e-3)"
      ],
      "metadata": {
        "id": "qqr_EtG6RMSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_on_trainset = model.evaluate(training_data)\n",
        "acc_on_testset = model.evaluate(testing_data)\n",
        "print(f\"Accuracy on trainset: {acc_on_trainset}\")\n",
        "print(f\"Accuracy on testset: {acc_on_testset}\")"
      ],
      "metadata": {
        "id": "yrm3GXb1hthZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(training_data, optimizer='adam', epochs=3, lr=1e-3)"
      ],
      "metadata": {
        "id": "bM1CkTQqderl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_on_trainset = model.evaluate(training_data)\n",
        "acc_on_testset = model.evaluate(testing_data)\n",
        "print(f\"Accuracy on trainset: {acc_on_trainset}\")\n",
        "print(f\"Accuracy on testset: {acc_on_testset}\")"
      ],
      "metadata": {
        "id": "CY_GqIxsdhhk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}