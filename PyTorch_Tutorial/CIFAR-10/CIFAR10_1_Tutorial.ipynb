{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_1_Tutorial.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXAWl6--Lvtn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset**"
      ],
      "metadata": {
        "id": "SeQrC59mV95i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    img = img.numpy()\n",
        "    plt.imshow(np.transpose(img, (1,2,0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "suqS1PBKVDeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")"
      ],
      "metadata": {
        "id": "zBw-7b0yUicE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n",
        "testing_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")"
      ],
      "metadata": {
        "id": "UyA0Vm2-GUvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [ \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "training_dataloader = DataLoader(training_data, batch_size=4, shuffle=False)\n",
        "Img, Lbl = next(iter(training_dataloader))\n",
        "imshow(torchvision.utils.make_grid(Img))\n",
        "print(' '.join(f'{class_names[Lbl[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "id": "rw1-ENDuKc9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "TBV4DuwBWEkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.Stage_1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.Stage_2 = nn.Flatten()\n",
        "        self.Stage_3 = nn.Sequential(\n",
        "            nn.Linear(16*5*5, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 10)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, X):\n",
        "        Stage_1 = self.Stage_1(X)\n",
        "        Stage_2 = self.Stage_2(Stage_1)\n",
        "        Stage_3 = self.Stage_3(Stage_2)\n",
        "        return Stage_3\n",
        "\n",
        "    def train(self, training_data, optimizer=\"sgd\", batch_size=64, epochs=10, lr=5e-6):\n",
        "        training_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        Loss = nn.CrossEntropyLoss()\n",
        "        if optimizer.lower()==\"adam\":\n",
        "            Optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "        else:\n",
        "            Optimizer = torch.optim.SGD(self.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "        print(\"-----------------------------------------------\")\n",
        "        for i in range(epochs):\n",
        "            for batch, (X, y) in enumerate(training_dataloader):\n",
        "                y_pre = self.forward(X)\n",
        "                loss_fn = Loss(y_pre, y)\n",
        "\n",
        "                Optimizer.zero_grad()\n",
        "                loss_fn.backward()\n",
        "                Optimizer.step()\n",
        "            if (i%10 == 0):\n",
        "                print(f\"-- Epoch {i}/{epochs}: Loss = {loss_fn}\")\n",
        "\n",
        "    def evaluate(self, testing_data):\n",
        "        corrected, total = 0, 0\n",
        "        testing_dataloader = DataLoader(testing_data, batch_size=1, shuffle=False)\n",
        "\n",
        "        for batch, (X, y) in enumerate(testing_dataloader):\n",
        "            y_pre = self.forward(X)\n",
        "            if (y_pre.argmax().item() == y.item()):\n",
        "                corrected += 1\n",
        "            total += 1\n",
        "        return (corrected / total) * 100"
      ],
      "metadata": {
        "id": "OYO66BEPV6Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, testing_data):\n",
        "    corrected, total = 0, 0\n",
        "    testing_dataloader = DataLoader(testing_data, batch_size=1, shuffle=False)\n",
        "\n",
        "    for batch, (X, y) in enumerate(testing_dataloader):\n",
        "        y_pre = model.forward(X)\n",
        "        if (y_pre.argmax().item() == y.item()):\n",
        "            corrected += 1\n",
        "        total += 1\n",
        "    return (corrected / total) * 100"
      ],
      "metadata": {
        "id": "T75bdmceisNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.train(training_data, optimizer='adam', epochs=100, lr=1e-3)"
      ],
      "metadata": {
        "id": "r-07u62a7ppi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_on_trainset = evaluate(model, training_data)\n",
        "acc_on_testset = evaluate(model, testing_data)\n",
        "print(f\"Accuracy on trainset: {acc_on_trainset}\")\n",
        "print(f\"Accuracy on testset: {acc_on_testset}\")"
      ],
      "metadata": {
        "id": "BU_Y_Oz_grtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Nhan xet: Model bi overfitting do so lan train qua nhieu (epochs=100)"
      ],
      "metadata": {
        "id": "tc77hE6ViiW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.train(training_data, optimizer='adam', epochs=30, lr=1e-3)"
      ],
      "metadata": {
        "id": "Eiuz_I-CioL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_on_trainset = model.evaluate(training_data)\n",
        "acc_on_testset = model.evaluate(testing_data)\n",
        "print(f\"Accuracy on trainset: {acc_on_trainset}\")\n",
        "print(f\"Accuracy on testset: {acc_on_testset}\")"
      ],
      "metadata": {
        "id": "mDQHGbDDi0gY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}