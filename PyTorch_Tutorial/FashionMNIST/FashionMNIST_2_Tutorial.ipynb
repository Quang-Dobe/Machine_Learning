{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMNIST_2_Tutorial.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD8uu8BXAVnP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # Stage 1: Input -> Conv2d -> ReLU -> MaxPool2d -> Conv2d -> ReLU -> MaxPool2d\n",
        "        self.Stage1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, 5, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=(2,2)),\n",
        "            nn.Conv2d(6, 16, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=(2,2))\n",
        "        )\n",
        "        # Stage 2: Stage_1 -> Flatten\n",
        "        self.Stage2 = nn.Flatten()\n",
        "        # Stage 3: Stage_2 -> Linear -> ReLU -> Linear -> Output\n",
        "        self.Stage3 = nn.Sequential(\n",
        "            nn.Linear(16*7*7, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "    \n",
        "    def forward(self, X):\n",
        "        y_stage1 = self.Stage1(X)\n",
        "        y_stage2 = self.Stage2(y_stage1)\n",
        "        y_stage3 = self.Stage3(y_stage2)\n",
        "        return y_stage3\n",
        "    \n",
        "    def train(self, training_data, batch_size=64, shuffle=True, optimizer=\"Adam\", epochs=10, lr=1e-3):\n",
        "        # Split dataset into batches for a training epoch\n",
        "        training_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=shuffle)\n",
        "        # Use Cross Entropy Loss\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        # Use Adam or SGD for optimizing\n",
        "        if optimizer.lower() == \"adam\":\n",
        "            optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "        elif optimizer.lower() == \"sgd\":\n",
        "            optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
        "        \n",
        "        for i in range(epochs):\n",
        "            for no, (X, y) in enumerate(training_dataloader):\n",
        "                y_pre = self.forward(X)\n",
        "                loss = loss_fn(y_pre, y)\n",
        "                # Gradient descent\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            print(f\"Epoch {i}: Loss = {loss}\")\n",
        "    \n",
        "    def Evaluate(self, testing_data):\n",
        "        X, y = testing_data.data, testing_data.targets\n",
        "        count, total = 0, 0\n",
        "\n",
        "        for index in range(X.size()[0]):\n",
        "            temp = torch.Tensor(X[index].numpy().reshape(1, 1, 28, 28))\n",
        "            y_pre = self.forward(temp)\n",
        "            total += 1\n",
        "            if (y[index].item() == y_pre.argmax(1).item()):\n",
        "                count += 1\n",
        "        return count/total*100"
      ],
      "metadata": {
        "id": "Xflmyjp1AoCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")\n",
        "testing_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "NUJxrD0zr1GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.train(training_data, batch_size=128, epochs=20)"
      ],
      "metadata": {
        "id": "VfSse9DGyLEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.Evaluate(testing_data)"
      ],
      "metadata": {
        "id": "QraNMSgG2W5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.Evaluate(training_data)"
      ],
      "metadata": {
        "id": "Zn_U0jvfNxd7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}